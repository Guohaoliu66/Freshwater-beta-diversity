##########
Calculating taxonomic and functional beta diversity based on Sørensen,
and partition beta into turnover and nestedness components
##########

# TD Sorensen dissimilarity
```{r}
pacman::p_load(tidyverse, readxl, glue, betapart)

data_dir <- "raw data"  ###  set the path of the "raw data" file
output_dir <- "output_file/output_TD"  ###  set the path of the "output_file/output_TD" file
dir.create(output_dir, showWarnings = FALSE)

file_list <- list.files(data_dir, pattern = "\\.xlsx$", full.names = TRUE)
dataset_names <- tools::file_path_sans_ext(basename(file_list))

for (i in seq_along(file_list)) {
  file <- file_list[i]
  name <- dataset_names[i]
  cat("Processing:", name, "\n")

  dat <- tryCatch(read_excel(file, sheet = "species") %>% as.data.frame(), error = function(e) NULL)
  if (is.null(dat)) {
    warning("Skipping ", name, " due to missing species sheet")
    next
  }

  rownames(dat) <- dat[[1]]
  dat <- dat[, -1]
  comm <- as.matrix(dat)

  comm <- comm[rowSums(comm) > 0, colSums(comm) > 0, drop = FALSE]
  if (nrow(comm) < 4 || ncol(comm) < 2) {
    warning("Skipping ", name, " due to insufficient rows/columns")
    next
  }

  comm_bin <- ifelse(comm > 0, 1, 0)

  beta_parts <- tryCatch(
    beta.pair(comm_bin, index.family = "sorensen"),
    error = function(e) {
      warning("Failed to compute beta.pair on ", name)
      return(NULL)
    }
  )

  if (!is.null(beta_parts)) {
    saveRDS(beta_parts, file = glue("{output_dir}/{name}_sor_parts.rds"))
    cat("Saved:", name, "\n")
  }
}

```

# FD Sorensen dissimilarity
```{r}
pacman::p_load(tidyverse, readxl, FD, betapart, vegan, ape, doSNOW, snow, foreach)

data_dir <- "raw data"  ###  set the path of the "raw data" file
output_dir <- "output_file/output_FD"  ###  set the path of the "output_file/output_FD" file
dir.create(output_dir, showWarnings = FALSE)

n_cores <- max(1, min(parallel::detectCores(logical = FALSE), 4))
cl <- snow::makeCluster(n_cores)
doSNOW::registerDoSNOW(cl)

files <- list.files(data_dir, pattern = "^[^~].*\\.xlsx$", full.names = TRUE)

for (file in files) {
  dataset_name <- tools::file_path_sans_ext(basename(file))
  cat("Processing：", dataset_name, "\n")

  tryCatch({
    trm <- read_excel(file, sheet = "traits") %>% as.data.frame()
    spm <- read_excel(file, sheet = "species") %>% as.data.frame()

    rownames(trm) <- trm$Species
    trm <- trm[, -1, drop = FALSE]
    rownames(spm) <- spm[, 1]
    spm <- spm[, -1, drop = FALSE]

    shared_species <- intersect(colnames(spm), rownames(trm))
    trm <- trm[shared_species, , drop = FALSE]
    spm <- spm[, shared_species, drop = FALSE]

    trm <- trm[, apply(trm, 2, function(x) length(unique(na.omit(x))) > 1), drop = FALSE]
    if (ncol(trm) < 1) {
      cat("Skip：", dataset_name, "due to insufficient rows/columns")
      next
    }

    gow <- gowdis(trm)
    pco <- ape::pcoa(gow)
    if (ncol(pco$vectors) < 2) {
      cat("Skip：", dataset_name, "insufficient PCoA dimensions\n")
      next
    }
    traits_pcoa2 <- pco$vectors[, 1:2]
    colnames(traits_pcoa2) <- c("PCoA1", "PCoA2")

    spm_bin <- decostand(spm, method = "pa")
    spm_bin <- spm_bin[rowSums(spm_bin) >= 3, , drop = FALSE]
    if (nrow(spm_bin) < 2) {
      cat("Skip：", dataset_name, "- insufficient sites\n")
      next
    }
    core_pair <- functional.betapart.core.pairwise(
      x = spm_bin,
      traits = traits_pcoa2,
      return.details = FALSE,
      parallel = TRUE,
      opt.parallel = beta.para.control(nc = n_cores),
      convhull.opt = list(conv1 = "QJ"),
      progress = TRUE
    )

    beta_result <- functional.beta.pair(core_pair, index.family = "sorensen")

    saveRDS(beta_result, file = file.path(output_dir, paste0(dataset_name, "_functional_beta.rds")))
    cat("Save success", dataset_name, "\n")

  }, error = function(e) {
    cat("error", dataset_name, "-", e$message, "\n")
  })
}

snow::stopCluster(cl)

```
